\section*{Chapter 3: Discrete Random Variables}
\begin{enumerate}
    \item Discrete Random Variables: Assign numerical value to discrete outcomes
    \item Probability Mass Function~(PMF): $$\sum_{x\in X}P_X(x)=1$$ 
    \item Families of Discrete Random Variables and their PMF{
        \begin{enumerate}
            \item Bernoulli(p): \textbf{E.g., Flip a coin}{
                \[ P_X(x) = 
                \begin{cases}
                    1-p & x=0, \\
                    p   & x=1, \\
                    0   & otherwise.
                \end{cases} \]
            }
            \item Binomial(n,p): Get \textbf{x} successes in \textbf{n} Bernoulli(p) experiments $\iff$ independent trails{
                $$P_X(\textcolor{red}{x}) = \binom{n}{\textcolor{red}{x}}p^x(1-p)^{n-x}$$.
            }
            \item Poisson($\alpha$): Binomial(n,p) with extremely small p (a.k.a. $\alpha$) and large n{
                \[ P_X(x) = 
                \begin{cases}
                    \dfrac{\alpha^xe^{-\alpha}}{x!}   & x=0,1,\ldots \\
                    0   & otherwise.
                \end{cases} \]
            }
            \item Geometric(p): Get the \textbf{1st} success at the \textbf{x-th} Bernoulli(p) experiment {
                \[ P_X(x) = 
                \begin{cases}
                    p(1-p)^{x-1} & x=1,2,\ldots \\
                    0   & otherwise.
                \end{cases} \]
            }
            \item Pascal(k,p): Get the \textbf{k-th} success at the \textbf{x-th} Bernoulli(p) experiment (Geometric(p) is Pascal(1,p)){
                $$P_X(\textcolor{red}{x}) = \binom{\textcolor{red}{x-1}}{k-1}p^k(1-p)^{x-k}$$.
            }
            \item Discrete Uniform(k,l): outcomes are uniformly distributed on range (k,l) \textbf{E.g., Roll a Dice}{
                \[ P_X(x) = 
                \begin{cases}
                    1/(l-k+1)   & x=k,k+1,k+2,\ldots,l \\
                    0   & otherwise.
                \end{cases} \]
            }            
        \end{enumerate}
    }
    \item Cumulative Distribution Function~(CDF): {
        \begin{align*}
            F_X(x)&=P_X[X\leq x] \\
            F_X(b)-F_X(a)&=P_X(a<X\leq b)
        \end{align*}
    }
    \item Average and Expectations{
        \begin{enumerate}
            \item In ordinary language, an \textbf{Average} is a single number taken as representative of a list of numbers.{
            \begin{enumerate}
                \item Mode: The outcome appears the most often in the sample space $$P_X(x_{mod})\geq P_X(x)$$
                \item Median: The outcome which separates the higher half from  the lower half of a sample space $$P[X\leq x_{med}]\geq 1/2 \qquad \qquad P[X\geq x_{med}]\geq 1/2$$
                \item (Arithmetic) mean:  The sum of all the outcomes divided by the number of outcomes $$\bar{x} = \frac{1}{n}\sum_{i=1}^{n}x_i$$
            \end{enumerate}
            }
            \item Expectations: Weighted (Arithmetic) mean{
                \begin{enumerate}
                    \item Definition:{
                        \begin{align}
                            \mu_x = \E{X}&=\sum_{x\in S_X}xP_X(x) \tag{First Moment of $X$}\\
                            \E{X^2}&=\sum_{x\in S_X}x^2P_X(x) \tag{Second Moment of $X$}
                        \end{align}
                    }
                    \item Important Expectations{
                        \begin{enumerate}
                            \item Bernoulli(p): $$\E{X}=0\cdot P_X(0)+1\cdot P_X(1)=0(1-p)+1(p)=p$$
                            \item Binomial(n,p): $$\E{X}=np$$
                            \item Poisson($\alpha$): $$\E{X}=\alpha$$
                            \item Geometric(p): $$\E{X}=\sum_{x=1}^{\infty}xP_X(x)=\sum_{x=1}^{\infty}xp(1-p)^{x-1}=\dfrac{p}{1-p}\sum_{x=1}^{\infty}x(1-p)^x=\dfrac{p}{1-p}\dfrac{1-p}{[1-(1-p)]^2}=\dfrac{p}{p^2}=\dfrac{1}{p}$$
                            \item Pascal(k,p): $$\E{X}=k/p$$
                            \item Discrete Uniform(k,l): $$\E{X}=(k+l)/2$$
                        \end{enumerate}
                    }
                \end{enumerate}
            }
            \item From an engineering perspective, \textbf{Mean (including Expectations, etc.)} is numerically easier to calculate, either using human brain or computers, than Mode and Median. 
        \end{enumerate}
    }
    \item Derived Random Variable: $Y = g(X)${
        \begin{enumerate}
            \item $P_Y(y) = P[Y=y] = P[Y=g(x)] = P[g^{-1}(Y)=g^{-1}(g(x))] = P[X=x] = P_X(x)$
            \item $\E{Y} = \sum yP_Y(y) = \sum g(x)P_X(x)$
            \item $\E{X-\mu_x}=\sum_{x\in S_X}(x-\mu_x)P_X(x)=\sum_{x\in S_X}xP_X(x)-\mu_x\sum_{x\in S_X}P_X(x)=\E{X}-\mu_x\cdot 1=\mu_x-\mu_x=0$
            \item $\E{aX+b}=a\E{X}+b \Rightarrow \E{b}=\E{0\cdot X+b}=b$
        \end{enumerate}
    }
    \item Variance($\sigma_x^2$) and Standard Deviation($\sigma_x$){
        \begin{enumerate}
            \item $\sigma_x^2=\Var(X)$ $$\Var(X)=\E{(X-\mu_x)^2}=\E{X^2-2\mu_xX+\mu_x^2}=\E{X^2}-2\mu_x\E{X}+\E{\mu_x^2}=\E{X^2}-2\mu_x^2+\mu_x^2=\E{X^2}-\mu_x^2$$
            \item $\Var(X)\geq 0$
            \item $\Var(aX+b)=a^2\Var(X)$
            \item Important Variance:{
                \begin{enumerate}
                    \item Bernoulli(p): $$\Var(X)=p(1-p)$$
                    \item Binomial(n,p): $$\Var(X)=np(1-p)$$
                    \item Poisson($\alpha$): $$\Var(X)=\alpha$$
                    \item Geometric(p): $$\Var(X)=(1-p)/p^2$$
                    \item Pascal(k,p): $$\Var(X)=k(1-p)/p^2$$
                    \item Discrete Uniform(k,l): $$\Var(X)=(l-k)(l-k+2)/12$$
                \end{enumerate}
            }
        \end{enumerate}
    }
\end{enumerate}