{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the record of my study progress on NTK. The plan is as follows.\n",
    "\n",
    "- Study the Neural Tangent Library by Google\n",
    "- Reproduce several works published in 2019 focusing on the basic property of NTK and being familiar with the code\n",
    "- TBD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following paper contains the development of the [neural-tangents](https://github.com/google/neural-tangents) library\n",
    "\n",
    "- [Neural Tangents: Fast and Easy Infinite Neural Networks in Python](https://arxiv.org/abs/1912.02803)\n",
    "- [Fast Finite Width Neural Tangent Kernel](https://arxiv.org/abs/2206.08720)\n",
    "- [Infinite attention: NNGP and NTK for deep attention networks](https://arxiv.org/abs/2006.10540)\n",
    "- [On the infinite width limit of neural networks with a standard parameterization](https://arxiv.org/abs/2001.07301)\n",
    "- [Fast Neural Kernel Embeddings for General Activations](https://arxiv.org/abs/2209.04121)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following paper contains the basic property of NTK in the early years, which will be used to be familiar with the [neural-tangents](https://github.com/google/neural-tangents) library.\n",
    "\n",
    "- NIPS 2019\n",
    "  - [Wide Neural Networks of Any Depth Evolve as Linear Models Under Gradient Descent](https://arxiv.org/pdf/1902.06720.pdf)\n",
    "  - [On Lazy Training in Differentiable Programming](https://arxiv.org/pdf/1812.07956.pdf)\n",
    "  - [The Convergence Rate of Neural Networks for Learned Functions of Different Frequencies](https://arxiv.org/pdf/1906.00425.pdf)\n",
    "  - [Limitations of Lazy Training of Two-layers Neural Networks](https://arxiv.org/pdf/1906.08899.pdf)\n",
    "  - [On the Inductive Bias of Neural Tangent Kernels](https://arxiv.org/pdf/1905.12173.pdf)\n",
    "- ICML 2020\n",
    "  - [Neural Kernels Without Tangents](https://arxiv.org/pdf/2003.02237.pdf)\n",
    "- arXiv\n",
    "  - [A Fine-Grained Spectral Perspective on Neural Networks](https://arxiv.org/pdf/1907.10599.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
